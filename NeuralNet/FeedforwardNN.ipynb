{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98d80eb-496a-4a3b-92c9-05b91811fdee",
   "metadata": {},
   "source": [
    "<h1> Feedforward Fully-connected Neuralnetwork </h1>\n",
    "\n",
    "\n",
    "<h3>Proto</h3>\n",
    "단순하게 학습정도만 구현할것임. 버전관리하면서 기능 추가해볼것  \n",
    "\n",
    "batch_size : size of mini-batch INT  \n",
    "n_iteration : number of iterations INT  \n",
    "n_neurons : number of neurons to hidden layer INT    \n",
    "n_layers : number of hidden layers INT    \n",
    "learning_rate : learning rate FLOAT    \n",
    "hidden_activation : activation function. [ 'sigmoid', 'relu' ]   \n",
    "output_activation : activation function for last layer. [ 'sigmoid', 'relu', 'softmax']  \n",
    "cost_function : cost function [ 'crossentropy', 'mse' ]  \n",
    "optimizer : gradient descent algorithm. [ 'minibatchSGD' ]  \n",
    "kernel_initializer : kernel initializer. [ 'he' ]  \n",
    "\n",
    "앞으로구현할것:  \n",
    "Crossentropy backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a32707-a8ec-4ef2-bad4-a2bcb78e0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e155a8e-bd59-4dae-aa1b-83504bd19d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "s = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(s,\n",
    "                 header=None,\n",
    "                 encoding='utf-8')\n",
    "\n",
    "y = df.iloc[0:100,4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "X = df.iloc[0:100, [0, 2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29dece13-5bc5-4697-8ab3-9e24990e97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyconnectedNN(object):\n",
    "    def __init__(self, n_iteration = 100, shuffle = True, batch_size = 20, n_neurons = 2, n_layers = 2, learning_rate = 0.1, hidden_activation = 'relu', output_activation = 'relu',\n",
    "                 cost_function = 'mse', optimizer = 'minibatchSGD', random_state = 42, kernel_initializer = 'he'):\n",
    "        self.n_iteration = n_iteration\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.output_activation = output_activation\n",
    "        self.cost_function_ = cost_function\n",
    "        self.optimizer = optimizer\n",
    "        self.random_state = random_state\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        \n",
    "    def fit(self, X, y):   \n",
    "        def mse(y_hat, y):\n",
    "            return np.square(np.subtract(y_hat, y)).mean()\n",
    "        def cross_entropy(y_hat, y):\n",
    "            #add delta to prevent y_hat to be zero\n",
    "            delta = 1e-7 \n",
    "            return -np.sum(y*np.log(y_hat+delta))\n",
    "        \n",
    "        \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        assert X.shape[0] == len(y), \"X and y don't match.\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        self.w_ = []\n",
    "        self.b_ = []\n",
    "        \n",
    "        if self.kernel_initializer == 'he':\n",
    "            scale = [np.sqrt(2/X.shape[1]), np.sqrt(2/self.n_neurons)]\n",
    "        else:\n",
    "            scale = [.1, .1]\n",
    "        \n",
    "        self.w_.append(rgen.normal(loc = .0, scale = scale[0], size = X.shape[1] * self.n_neurons).reshape(X.shape[1], self.n_neurons))\n",
    "        self.b_.append(rgen.normal(loc = .0, scale = scale[0], size = self.n_neurons))\n",
    "        for _ in range(self.n_layers - 1):\n",
    "            self.w_.append(rgen.normal(loc = .0, scale = scale[1], size = np.power(self.n_neurons,2)).reshape(self.n_neurons,self.n_neurons))\n",
    "            self.b_.append(rgen.normal(loc = .0, scale = scale[1], size = self.n_neurons))\n",
    "            \n",
    "        if self.cost_function_ in ['crossentropy']:\n",
    "            self.w_.append(rgen.normal(loc = .0, scale = scale[1], size = len(Counter(y)) * self.n_neurons).reshape(len(Counter(y)), self.n_neurons))\n",
    "            self.b_.append(rgen.normal(loc = .0, scale = scale[1], size = len(Counter(y))))\n",
    "        else:\n",
    "            self.w_.append(rgen.normal(loc = .0, scale = scale[1], size = self.n_neurons))\n",
    "            self.b_.append(rgen.normal(loc = .0, scale = scale[1], size = 1))\n",
    "        \n",
    "        \n",
    "        self.cost_ = []\n",
    "        \n",
    "        def create_minibatches(y):\n",
    "            indices = np.arange(len(y))\n",
    "            if self.shuffle:\n",
    "                rgen.shuffle(indices)\n",
    "            cut = [x for x in range(0, len(indices), self.batch_size)] + [len(indices)]\n",
    "            mini_batches = []\n",
    "            for i in range(1,len(cut)):\n",
    "                mini_batches.append(indices[cut[i-1]:cut[i]])\n",
    "            return mini_batches\n",
    "        \n",
    "        self.w_change_ = []\n",
    "        for _ in range(self.n_iteration):\n",
    "            batches = create_minibatches(y)\n",
    "            cost = []\n",
    "            for batch in batches:\n",
    "                X_batch = X[tuple(batch),:]\n",
    "                y_batch = [y[int(batch_idx)] for batch_idx in batch]\n",
    "                \n",
    "                #forward-propagation\n",
    "                self._y_hat = self.predict(X_batch)\n",
    "                if self.cost_function_ == 'crossentropy':\n",
    "                    cost.append(cross_entropy(self._y_hat, y_batch))\n",
    "                if self.cost_function_ == 'mse':\n",
    "                    cost.append(mse(self._y_hat, y_batch))\n",
    "                \n",
    "                #back-propagation\n",
    "                self._d = []\n",
    "                for i in range(1,self.n_layers + 1):\n",
    "                    if self.cost_function_ == 'mse':\n",
    "                        if i == 1:\n",
    "                            self._d.append( ((self._y_hat - y_batch) * self._o_prime[-1]).mean(axis = 0) )\n",
    "                            self.w_[-1] = self.w_[-1] - (self.learning_rate * self._d[-1] * self._o[-1].mean(axis = 0))\n",
    "                            self.b_[-1] = self.b_[-1] - (self.learning_rate * self._d[-1])\n",
    "                        else:\n",
    "                            self._d.append( self._o_prime[-i].mean(axis = 0) *  np.sum(np.dot(self._d[-1], self.w_[-(i-1)].T), axis = 0) )\n",
    "                            self.w_[-i] = self.w_[-i] - (self.learning_rate * np.dot(self._d[-1][:,None], self._o[-i].mean(axis = 0)[:,None].T) ).T\n",
    "                            self.b_[-i] = self.b_[-i] - (self.learning_rate * self._d[-1])\n",
    "                \n",
    "                else:\n",
    "                    self._d.append( self._o_prime[0].mean(axis = 0) * np.sum(np.dot(nn._d[1], nn.w_[1].T), axis = 0) )\n",
    "                    self.w_[0] = self.w_[0] - (self.learning_rate * np.dot(self._d[-1][:,None], X_batch.mean(axis = 0)[:,None].T) ).T\n",
    "                    self.b_[0] = self.b_[0] - (self.learning_rate * self._d[-1])\n",
    "\n",
    "            self.cost_.append(sum(cost)/len(cost))\n",
    "        \n",
    "        return self\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        def softmax(z):\n",
    "            assert len(z.shape) == 2\n",
    "            s = np.max(z, axis=1)\n",
    "            s = s[:, np.newaxis]\n",
    "            e_x = np.exp(z - s)\n",
    "            div = np.sum(e_x, axis=1)\n",
    "            div = div[:, np.newaxis]\n",
    "            return e_x / div\n",
    "        self._o = []\n",
    "        self._o_prime = []\n",
    "        \n",
    "        if self.hidden_activation == 'sigmoid':\n",
    "            hidden_activation = lambda x:1/(1+np.exp(-x))\n",
    "            def hidden_activation_prime(x):\n",
    "                rev = (1-activation(x))\n",
    "                return activation(x) * rev\n",
    "        if self.hidden_activation == 'relu':\n",
    "            hidden_activation = lambda x:np.maximum(x,0)\n",
    "            hidden_activation_prime = lambda x:np.heaviside(x,0)\n",
    "        \n",
    "        if self.output_activation == 'sigmoid':\n",
    "            output_activation = lambda x:1/(1+np.exp(-x))\n",
    "            def output_activation_prime(x):\n",
    "                rev = (1-activation(x))\n",
    "                return activation(x) * rev\n",
    "        if self.output_activation == 'relu':\n",
    "            output_activation = lambda x:np.maximum(x,0)\n",
    "            output_activation_prime = lambda x:np.heaviside(x,0)\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            if i == 0:\n",
    "                o_ = np.matmul(X, self.w_[i]) + self.b_[i]\n",
    "                self._o.append(hidden_activation(o_))\n",
    "                self._o_prime.append(hidden_activation_prime(o_))\n",
    "                \n",
    "            else:\n",
    "                o_ = np.matmul(self._o[i-1], self.w_[i]) + self.b_[i]\n",
    "                self._o.append(hidden_activation(o_))\n",
    "                self._o_prime.append(hidden_activation_prime(o_))\n",
    "                    \n",
    "        o_ = np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers]\n",
    "        self._o_prime.append(output_activation_prime(o_))\n",
    "        return output_activation(o_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13ef6640-485f-4f5f-a2d2-6795b5286faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = FullyconnectedNN(output_activation='sigmoid', hidden_activation='relu', learning_rate=0.005, n_layers= 2, n_neurons = 5, n_iteration = 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e4e6023-26b1-4356-8ea8-9996a286e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FullyconnectedNN at 0x2607ca43b80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae1212e-fdd7-4080-a66b-eda55c2edeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2607ca22be0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYyElEQVR4nO3df5AX933f8edLh0EZLMVgnTQpPwSSL1VwrYJ9AXnU8WgcY2GpI8hEiZCsCWk81iixplWZtkGFMRE1E8XuaJRM6dg4VZsUqyCrCSEWlobY0jRxjMxhMBhkzIEUxFUxFyEZ10Yg0Lt/fBezfH333b277/e7393v6zFzc9/d/ez33t+VeH33+9nP97OKCMzMrLouK7oAMzNrLQe9mVnFOejNzCrOQW9mVnEOejOziptUdAH1rrrqqpgzZ07RZZiZlcru3bv/MSJ6R9rWcUE/Z84cBgYGii7DzKxUJP39aNvcdWNmVnEOejOzissV9JKWSDokaVDSqhG23y9pv6S9kv5W0rxk/RxJp5P1eyV9vtkvwMzMGsvso5fUA2wAFgPHgV2StkXEwVSzJyLi80n7O4BHgSXJtiMRMb+pVZuZWW55zugXAoMRcTQizgKbgaXpBhFxKrU4FfAEOmZmHSLPqJsZwCup5ePAovpGkj4FrAQmAx9ObZoraQ9wClgTEX8z/nJHt3XPEJ979hD/943T/JN3/Rz//tZ/yrIFM1rxp8zMSqVpF2MjYkNEXA/8HrAmWf0qMDsiFlB7E3hC0pX1+0q6T9KApIHh4eEx/+2te4ZYuWUvQ2+cJoChN06zcstetu4ZGv8LMjOriDxBPwTMSi3PTNaNZjOwDCAizkTEa8nj3cAR4Bfrd4iIjRHRHxH9vb0jjvdv6KE/38fbdeveTtabmXW7PF03u4A+SXOpBfxy4J50A0l9EXE4WbwdOJys7wVORsR5SdcBfcDRZhV/wem36mP+4voLXTpDb5z+6foeibsXzeIzy97X7FLMzDpOZtBHxDlJDwDPAj3A4xFxQNI6YCAitgEPSPoI8BbwOrAi2f1DwDpJb1E7yb4/Ik624oWM5sEte39m3fkINu08xqadx3j5kdvbWY6ZWdup0+4w1d/fH2OdAmHOqqcn9Dcd9mZWdpJ2R0T/SNv8zVhqbxS+cGtmVeWgTzzoUTpmVlEO+pR/O0J/vplZ2TnoUwJ8Vm9mlVOJoL9MzXsud+GYWdVUIujvWTS7qc830pBMM7OyqkTQj+WLT1dO6WlhJWZmnacSQT8W+x5ekt0IuHHtMy2uxMysPboq6O+9qdbFc/P10zPbnjpzvtXlmJm1RWWC/porJme2udDF86VPfjBXezOzKqhM0L+wenHD7fXBntUe4D0PTWxqBTOzTlCZoIfR56y55orJIwb7Y3fNb/h85wIWP/p8EyozMytOJSY1m4g8E6Lde9NsT2lsZh3Nk5o10Hf11Mw2m3Yea0MlZmat0fVBv2PlLUWXYGbWUl0f9GZmVeeg5+L4+kY8/42ZlZWDntr4+qyw9/w3ZlZWDvpEnlE1a7bub0MlZmbN5aBPyZru2KNvzKyMHPQpzZ7u2MysEzjoU/J033haBDMrGwd9naybVZ0Lj8Axs3Jx0Nd5aZT5ctI8AsfMyiRX0EtaIumQpEFJq0bYfr+k/ZL2SvpbSfNS2x5K9jsk6dZmFm9mZtkyg15SD7AB+BgwD7g7HeSJJyLifRExH/gs8Giy7zxgOfBeYAnwX5Pn62h55r/xUEszK4s8Z/QLgcGIOBoRZ4HNwNJ0g4g4lVqcClyYEnMpsDkizkTES8Bg8nwdLc/8Nx5qaWZlkSfoZwCvpJaPJ+suIelTko5QO6P/12Pc9z5JA5IGhoeH89beUnnO6s3MyqBpF2MjYkNEXA/8HrBmjPtujIj+iOjv7e1tVkkTkues3jclMbMyyBP0Q8Cs1PLMZN1oNgPLxrlvR8ma/+bwiR+3qRIzs/HLE/S7gD5JcyVNpnZxdVu6gaS+1OLtwOHk8TZguaQpkuYCfcC3Jl52e+T5ApXH1JtZp8sM+og4BzwAPAu8CDwZEQckrZN0R9LsAUkHJO0FVgIrkn0PAE8CB4FngE9FxPnmv4zieEy9mXW6rr9nbJY1W/dnjrDxPWXNrGi+Z+wE5AlwD7U0s07moM/BQy3NrMwc9DnkGWr58S9+s/WFmJmNg4O+Sb5x5GTRJZiZjchBn1OeG4ibmXUiB31OHlNvZmXloB+DK6c0nnjTY+rNrBM56Mdg38NLii7BzGzMHPRmZhXnoB+jm6+f3nD7Dau3t6kSM7N8HPRj9KVPfrDh9jfPd9aUEmZmDvoW8Dz1ZtZJHPTjcJkab/c89WbWSRz04/Dob8wvugQzs9wc9OOwbMEMJmWc1c9Z9XR7ijEzy+CgH6fBP7g9s40nOjOzTuCgbyFPdGZmncBBPwFZ3TdmZp3AQT8BebpvPNGZmRXNQT9B11wxueH2lZ7ozMwK5qCfoBdWL264/e021WFmNhoHfRt49I2ZFclB3wRZ3TcefWNmRcoV9JKWSDokaVDSqhG2r5R0UNI+SV+TdG1q23lJe5Ofbc0svlNkdd+YmRVpUlYDST3ABmAxcBzYJWlbRBxMNdsD9EfETyT9DvBZ4K5k2+mImN/css3MLK88Z/QLgcGIOBoRZ4HNwNJ0g4h4LiJ+kizuBGY2t8zOl3Xz8Pc85CkRzKwYeYJ+BvBKavl4sm40nwC+mlq+XNKApJ2Slo20g6T7kjYDw8PDOUrqPFk3Dz/naerNrCBNvRgr6V6gH/hcavW1EdEP3AM8Jun6+v0iYmNE9EdEf29vbzNL6ihrtu4vugQz60J5gn4ImJVanpmsu4SkjwCrgTsi4syF9RExlPw+CjwPLJhAvR1t6uSehts37TzWpkrMzC7KE/S7gD5JcyVNBpYDl4yekbQA+AK1kD+RWj9N0pTk8VXAzUD6Im6lrP/Vxt034CkRzKz9MoM+Is4BDwDPAi8CT0bEAUnrJN2RNPsc8E7gy3XDKH8JGJD0HeA54JG60TqVsmxBo0sXNQ//1YE2VGJmdlHm8EqAiNgObK9b9+nU44+Mst/fAdmnuRXSd/XUhrcSfP0nb7WxGjMzfzO26XasvKXoEszMLuGgNzOrOAd9C2TNfbP40efbU4iZGQ76lsia+6ZRH76ZWbM56M3MKs5BXxB335hZuzjoW+Tm66c33O7uGzNrFwd9i3zpkx8sugQzM8BB31KTLlPRJZiZOehb6T//+j9vuP3Gtc+0qRIz62YO+hbKmvvm1JnzbarEzLqZg97MrOIc9C2WNUe9u2/MrNUc9C2WNUe9u2/MrNUc9C2WZ476j3/xm22oxMy6lYO+DS7vaTzM8htHTrapEjPrRg76Nvje+tuKLsHMupiDvkO4+8bMWsVB3yZZc9+4+8bMWsVB3yZ55r7ZumeoDZWYWbdx0HeQ3992oOgSzKyCHPRt9Nhd8xtuf+P0W+0pxMy6ioO+jfKMqTcza7ZcQS9piaRDkgYlrRph+0pJByXtk/Q1Sdemtq2QdDj5WdHM4ssoa0y9mVmzZQa9pB5gA/AxYB5wt6R5dc32AP0RcSPwFPDZZN/pwFpgEbAQWCtpWvPKL5+sMfUeZmlmzZbnjH4hMBgRRyPiLLAZWJpuEBHPRcRPksWdwMzk8a3Ajog4GRGvAzuAJc0pvZo8zNLMmi1P0M8AXkktH0/WjeYTwFfHsq+k+yQNSBoYHh7OUZKZmeXV1Iuxku4F+oHPjWW/iNgYEf0R0d/b29vMkjpS1h0G12zd355CzKwr5An6IWBWanlmsu4Skj4CrAbuiIgzY9m329yzaHbD7Zt2HmtTJWbWDfIE/S6gT9JcSZOB5cC2dANJC4AvUAv5E6lNzwIflTQtuQj70WRdV/vMssZz1JuZNdOkrAYRcU7SA9QCugd4PCIOSFoHDETENmpdNe8EviwJ4FhE3BERJyX9J2pvFgDrIsJXG83M2kgRUXQNl+jv74+BgYGiy2i5xY8+z+ETPx51e9/VU9mx8pb2FWRmpSZpd0T0j7TN34wtSFaIN3oTMDMbCwd9B/NslmbWDA76Al1zxeSG2x/csrc9hZhZpTnoC/TC6sVFl2BmXcBBb2ZWcQ76gmXdYvCG1dvbVImZVZWDvmBZtxh883xnDX81s/Jx0HeArLlvzMwmwkHfAR79jfkNt3uOejObCAd9B8i6xaDnqDeziXDQl4S/PGVm4+Wg7xBTJjX+T+EvT5nZeDnoO8Qf/tqNRZdgZhXloO8QWf30UJvx0sxsrBz0JeIZLc1sPBz0HSTrW7LgoZZmNnYO+g6S9S1Z8FBLMxs7B32H6bt6atElmFnFOOg7TJ7bB7r7xszGwkHfgS7vaTz5jbtvzGwsHPQd6Hvrbyu6BDOrEAd9SXlMvZnl5aDvUFlDLT2m3szyyhX0kpZIOiRpUNKqEbZ/SNK3JZ2TdGfdtvOS9iY/25pVeNXlGWrpi7JmlsekrAaSeoANwGLgOLBL0raIOJhqdgz4LeDfjfAUpyNi/sRLtXq+KGtmeeQ5o18IDEbE0Yg4C2wGlqYbRMTLEbEPeLsFNXate2+andnGffVmliVP0M8AXkktH0/W5XW5pAFJOyUtG6mBpPuSNgPDw8NjeOpq+8yy92W2cV+9mWVpx8XYayOiH7gHeEzS9fUNImJjRPRHRH9vb28bSiqPrDH1ZmZZ8gT9EDArtTwzWZdLRAwlv48CzwMLxlBf18szpv6G1dvbUImZlVWeoN8F9EmaK2kysBzINXpG0jRJU5LHVwE3Awcb72X1rpzS03D7m+fDtxo0s1FlBn1EnAMeAJ4FXgSejIgDktZJugNA0i9LOg78OvAFSQeS3X8JGJD0HeA54JG60TqWw76Hl2S2WelbDZrZKDKHVwJExHZge926T6ce76LWpVO/398B2VcULdM1V0zmBz86O+p2D3cys9H4m7El8cLqxZlt3H1jZiNx0JdI1vibB919Y2YjcNCXyEuP3F50CWZWQg56M7OKc9CXTNa0CHNXPd2mSsysLBz0JZM1LUIAa7bub08xZlYKDvoK2rTzWNElmFkHcdCbmVWcg76Esu4+Bb4piZld5KAvoTx3n/JNSczsAgd9Sb3sMfVmlpODvsIWrd9RdAlm1gEc9CXWd/XUhtsbTYJmZt3DQV9iO1beUnQJZlYCDvqK883DzcxBX3JZUyL45uFm5qAvuawpEcBn9WbdzkFfAVn3lPVZvVl3c9BXQJ57yvqs3qx7Oei7hM/qzbqXg74issbUA8zxXPVmXclBXxF5x9TfuPaZ1hZiZh3HQV8heea/OXXmfBsqMbNOkivoJS2RdEjSoKRVI2z/kKRvSzon6c66bSskHU5+VjSrcBu/Oaue9l2ozLpIZtBL6gE2AB8D5gF3S5pX1+wY8FvAE3X7TgfWAouAhcBaSdMmXraNJusLVBds2nmMG1Zvb3E1ZtYJ8pzRLwQGI+JoRJwFNgNL0w0i4uWI2Ae8XbfvrcCOiDgZEa8DO4DssYA2bnm+QHXBm+eDOaueZuueoRZWZGZFyxP0M4BXUsvHk3V55NpX0n2SBiQNDA8P53xqG81Y56p/cMtej8gxq7BJRRcAEBEbgY0A/f39UXA5lfDyI7ePObzT7W++fnquO1mZWefLE/RDwKzU8sxkXR5DwC11+z6fc1+boMt7xJvnx/e++Y0jJy8J/sfums+yBXk/yJlZJ1FE4yCQNAn4PvAr1IJ7F3BPRBwYoe3/AL4SEU8ly9OB3cD7kybfBj4QEaPe0LS/vz8GBgbG/kpsRDes3j7usG/EZ/xmnUXS7ojoH3FbVtAnT3Ab8BjQAzweEeslrQMGImKbpF8G/gKYBrwJ/ENEvDfZ97eB/5g81fqI+O+N/paDvjXa0Qfvs36z4kw46NvJQd86RVxw9U3MzdrDQW+XKHqEzTVXTOaF1YsLrcGsahz09jPWbN3Ppp3Hii7jp/qunup74JpNgIPeMhV9lj+SSYLBP3DXj1keDnobk04726/nET9mP8tBbxPS6cEPte8MfG/9bUWXYVYYB7013dY9Qzy4ZW/RZWTyqB/rFg56awuf+ZsVx0FvhZq76mk66/+ykfkLX1ZmDnrrOJ04yqeex/tbmTjorRRaNS9Ps/nM3zqRg95Kyxd9zfJx0FvlvOehpznXWf/rjshf+rJ2cdBbVyjDqJ8L/KUvazYHvXWtspz5X+A5f2y8HPRmdcr2BnDvTbPHdON36z4OerMcyjDkM81f/rI0B73ZOH38i9/kG0dGvfNlxxHwkkcAdSUHvVkTLX70eQ6f+HHRZYyJ+/6rz0Fv1iY3rn2GU2fOF11Gbv7yV3U46M0KVrb+fw//LB8HvVmHKtsbgK8BdC4HvVnJlO0NADwNRNEc9GYVUJZJ3+r5U0B7TDjoJS0B/gjoAf4kIh6p2z4F+DPgA8BrwF0R8bKkOcCLwKGk6c6IuL/R33LQm+W3aP0OfvCjs0WXMSG+HtAcEwp6ST3A94HFwHFgF3B3RBxMtfld4MaIuF/ScuBXI+KuJOi/EhH/LG+xDnqziStj189IrpzSw76HlxRdRik0CvpJOfZfCAxGxNHkyTYDS4GDqTZLgd9PHj8F/BdJGnfFZjYhI/WXl2XK57RTZ843fNPydYF88gT9DOCV1PJxYNFobSLinKQfAu9Ots2VtAc4BayJiL+p/wOS7gPuA5g9e/aYXoCZ5bNswYxRx8yX9RNAVt3+nkBNnqCfiFeB2RHxmqQPAFslvTciTqUbRcRGYCPUum5aXJOZ1RntzLhsXwCr9+CWvQ0/xXTLZHF5gn4ImJVanpmsG6nNcUmTgJ8HXovaBYAzABGxW9IR4BcBd8KblcBo/eNl7AYayaadx3Ldw6DsU0jkCfpdQJ+kudQCfTlwT12bbcAK4JvAncDXIyIk9QInI+K8pOuAPuBo06o3s0I06gYq+6eAkRw+8eNc3VudOoIo7/DK24DHqA2vfDwi1ktaBwxExDZJlwP/E1gAnASWR8RRSb8GrAPeAt4G1kbEXzX6Wx51Y1ZtZb0e0ArN7DryF6bMrBTmrnqazkqkYoznXsMOejMrvapcF8hrrGE/0XH0ZmaFa3Rd4IIqdQs181aXDnozq4xGX6Dqtk8EaQ56M+sKeT4RXFClTwbgoDcz+xl5p1Zo5RvCpCZOIuOgNzMbp7HOtZP3jWE8o24aPl/TnsnMzBoqahK2ywr5q2Zm1jYOejOzinPQm5lVnIPezKziHPRmZhXXcXPdSBoG/n4CT3EV8I9NKqfsfCwu5eNxKR+Pi6pwLK6NiN6RNnRc0E+UpIHRJvbpNj4Wl/LxuJSPx0VVPxbuujEzqzgHvZlZxVUx6DcWXUAH8bG4lI/HpXw8Lqr0sahcH72ZmV2qimf0ZmaW4qA3M6u4ygS9pCWSDkkalLSq6HpaRdLjkk5I+m5q3XRJOyQdTn5PS9ZL0h8nx2SfpPen9lmRtD8saUURr2WiJM2S9Jykg5IOSPo3yfpuPR6XS/qWpO8kx+PhZP1cSS8kr3uLpMnJ+inJ8mCyfU7quR5K1h+SdGtBL2nCJPVI2iPpK8lydx6LiCj9D9ADHAGuAyYD3wHmFV1Xi17rh4D3A99NrfsssCp5vAr4w+TxbcBXAQE3AS8k66cDR5Pf05LH04p+beM4Fr8AvD95fAXwfWBeFx8PAe9MHr8DeCF5nU8Cy5P1nwd+J3n8u8Dnk8fLgS3J43nJv6EpwNzk31ZP0a9vnMdkJfAE8JVkuSuPRVXO6BcCgxFxNCLOApuBpQXX1BIR8X+Ak3WrlwJ/mjz+U2BZav2fRc1O4F2SfgG4FdgREScj4nVgB7Ck5cU3WUS8GhHfTh7/CHgRmEH3Ho+IiP+XLL4j+Qngw8BTyfr643HhOD0F/IokJes3R8SZiHgJGKT2b6xUJM0Ebgf+JFkWXXosqhL0M4BXUsvHk3Xd4pqIeDV5/A/ANcnj0Y5L5Y5X8lF7AbWz2K49HklXxV7gBLU3rCPAGxFxLmmSfm0/fd3J9h8C76Y6x+Mx4D8AbyfL76ZLj0VVgt4SUfu82VVjZiW9E/jfwIMRcSq9rduOR0Scj4j5wExqZ543FFtRMST9S+BEROwuupZOUJWgHwJmpZZnJuu6xQ+SLgiS3yeS9aMdl8ocL0nvoBbyX4qIP09Wd+3xuCAi3gCeAz5IrYvqwm1D06/tp6872f7zwGtU43jcDNwh6WVqXbkfBv6I7jwWlQn6XUBfckV9MrWLKdsKrqmdtgEXRoqsAP4ytf43k9EmNwE/TLo0ngU+KmlaMiLlo8m6Ukn6UP8b8GJEPJra1K3Ho1fSu5LHPwcspnbd4jngzqRZ/fG4cJzuBL6efALaBixPRqLMBfqAb7XlRTRJRDwUETMjYg61PPh6RHycLjwWQDVG3dT+e3AbtVEXR4DVRdfTwtf5v4BXgbeo9Rd+glpf4teAw8BfA9OTtgI2JMdkP9Cfep7fpnZhaRD4V0W/rnEei39BrVtmH7A3+bmti4/HjcCe5Hh8F/h0sv46auE0CHwZmJKsvzxZHky2X5d6rtXJcToEfKzo1zbB43ILF0fddOWx8BQIZmYVV5WuGzMzG4WD3sys4hz0ZmYV56A3M6s4B72ZWcU56M3MKs5Bb2ZWcf8fFPk2xKo0/EwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#random initializer\n",
    "#lr = .01\n",
    "#iteration = 30000\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(1,len(nn.cost_)+1), nn.cost_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
