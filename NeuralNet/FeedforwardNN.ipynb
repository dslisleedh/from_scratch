{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98d80eb-496a-4a3b-92c9-05b91811fdee",
   "metadata": {},
   "source": [
    "<h1> Feedforward Fully-connected Neuralnetwork </h1>\n",
    "\n",
    "\n",
    "<h3>Proto</h3>\n",
    "단순하게 학습정도만 구현할것임. 버전관리하면서 기능 추가해볼것  \n",
    "\n",
    "batch_size : size of mini-batch INT  \n",
    "n_iteration : number of iterations INT  \n",
    "n_neurons : number of neurons to hidden layer INT    \n",
    "n_layers : number of hidden layers INT    \n",
    "learning_rate : learning rate FLOAT    \n",
    "hidden_activation : activation function. [ 'sigmoid', 'relu' ]   \n",
    "output_activation : activation function for last layer. [ 'sigmoid', 'relu', 'softmax']  \n",
    "cost_function : cost function [ 'crossentropy', 'mse' ]  \n",
    "optimizer : gradient descent algorithm. [ 'minibatchSGD' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a32707-a8ec-4ef2-bad4-a2bcb78e0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "3e155a8e-bd59-4dae-aa1b-83504bd19d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "s = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(s,\n",
    "                 header=None,\n",
    "                 encoding='utf-8')\n",
    "\n",
    "y = df.iloc[0:100,4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "X = df.iloc[0:100, [0, 2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "29dece13-5bc5-4697-8ab3-9e24990e97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyconnectedNN(object):\n",
    "    def __init__(self, n_iteration = 1000, shuffle = True, batch_size = 32, n_neurons = 2, n_layers = 2, learning_rate = 0.1, hidden_activation = 'relu', output_activation = 'relu',\n",
    "                 cost_function = 'mse', optimizer = 'minibatchSGD', random_state = 42):\n",
    "        self.n_iteration = n_iteration\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.output_activation = output_activation\n",
    "        self.cost_function_ = cost_function\n",
    "        self.optimizer = optimizer\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):   \n",
    "        def softmax(z):\n",
    "            assert len(z.shape) == 2\n",
    "            s = np.max(z, axis=1)\n",
    "            s = s[:, np.newaxis]\n",
    "            e_x = np.exp(z - s)\n",
    "            div = np.sum(e_x, axis=1)\n",
    "            div = div[:, np.newaxis]\n",
    "            return e_x / div\n",
    "        def mse(y_hat, y):\n",
    "            return np.square(np.subtract(y_hat, y)).mean()\n",
    "        def cross_entropy(y_hat, y):\n",
    "            #add delta to prevent y_hat to be zero\n",
    "            delta = 1e-7 \n",
    "            return -np.sum(y*np.log(y_hat+delta))\n",
    "        \n",
    "        \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        assert X.shape[0] == len(y), \"X and y don't match.\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        self.w_ = []\n",
    "        self.b_ = []\n",
    "        self.w_.append(abs(rgen.normal(loc = .0, scale = .01, size = X.shape[1] * self.n_neurons).reshape(X.shape[1], self.n_neurons)))\n",
    "        self.b_.append(abs(rgen.normal(loc = .0, scale = .01, size = self.n_neurons)))\n",
    "        for _ in range(self.n_layers - 1):\n",
    "            self.w_.append(abs(rgen.normal(loc = .0, scale = .01, size = np.power(self.n_neurons,2)).reshape(self.n_neurons,self.n_neurons)))\n",
    "            self.b_.append(abs(rgen.normal(loc = .0, scale = .01, size = self.n_neurons)))\n",
    "\n",
    "        if self.cost_function_ in ['crossentropy']:\n",
    "            self.w_.append(rgen.normal(loc = .0, scale = .01, size = len(Counter(y)) * self.n_neurons).reshape(len(Counter(y)), self.n_neurons))\n",
    "            self.b_.append(rgen.normal(loc = .0, scale = .01, size = len(Counter(y))))\n",
    "        else:\n",
    "            self.w_.append(rgen.normal(loc = .0, scale = .01, size = self.n_neurons))\n",
    "            self.b_.append(rgen.normal(loc = .0, scale = .01, size = 1))\n",
    "        \n",
    "        \n",
    "        self.cost_ = []\n",
    "        \n",
    "        def create_minibatches(y):\n",
    "            indices = np.arange(len(y))\n",
    "            if self.shuffle:\n",
    "                rgen.shuffle(indices)\n",
    "            cut = [x for x in range(0, len(indices), self.batch_size)] + [len(indices)]\n",
    "            mini_batches = []\n",
    "            for i in range(1,len(cut)):\n",
    "                mini_batches.append(indices[cut[i-1]:cut[i]])\n",
    "            return mini_batches\n",
    "\n",
    "        for _ in range(self.n_iteration):\n",
    "            batches = create_minibatches(y)\n",
    "            cost = []\n",
    "            for batch in batches:\n",
    "                X_batch = X[tuple(batch),:]\n",
    "                y_batch = [y[int(batch_idx)] for batch_idx in batch]\n",
    "                #forward-propagation\n",
    "                self._y_hat = self.predict(X_batch)\n",
    "                if self.cost_function_ == 'crossentropy':\n",
    "                    cost.append(cross_entropy(self._y_hat, y_batch))\n",
    "                if self.cost_function_ == 'mse':\n",
    "                    cost.append(mse(self._y_hat, y_batch))\n",
    "                \n",
    "                #back-propagation\n",
    "                self._d = []\n",
    "                for i in range(1,self.n_layers + 1):\n",
    "                    if self.cost_function_ == 'mse':\n",
    "                        if i == 1:\n",
    "                            self._d.append( ((self._y_hat - y_batch) * self._o_prime[-1]).mean(axis = 0) )\n",
    "                            self.w_[-i] -= self.learning_rate * self._d[-1] * self._o[-1].mean(axis = 0)\n",
    "                            self.b_[-i] -= self.learning_rate * self._d[-1]\n",
    "                        else:\n",
    "                            self._d.append( self._o_prime[-i].mean(axis = 0) *  np.dot(nn.w_[-(i-1)], nn._d[-1]) )\n",
    "                            self.w_[-i] -= self.learning_rate * self._d[-1] * self._o[-i].mean(axis = 0)\n",
    "                            self.b_[-i] -= self.learning_rate * self._d[-1]\n",
    "                \n",
    "                else:\n",
    "                    self._d.append( self._o_prime[-i].mean(axis = 0) * np.dot(nn.w_[1], self._d[-1] ) )\n",
    "                    self.w_[0] -= self.learning_rate * self._d[-1] * X.mean(axis = 0)\n",
    "                    self.b_[0] -= self.learning_rate * self._d[-1]\n",
    "\n",
    "            self.cost_.append(sum(cost)/len(cost))\n",
    "        \n",
    "        return self\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        self._o = []\n",
    "        self._o_prime = []\n",
    "        sigmoid = lambda x:1/(1+np.exp(-x))\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            if i == 0:\n",
    "                if self.hidden_activation == 'relu':\n",
    "                    self._o.append(np.maximum(np.matmul(X, self.w_[i]) + self.b_[i], 0))\n",
    "                    self._o_prime.append(np.heaviside(np.matmul(X, self.w_[i]) + self.b_[i], 0))\n",
    "                if self.hidden_activation == 'sigmoid':\n",
    "                    self._o.append(sigmoid(np.matmul(X, self.w_[i]) + self.b_[i]))\n",
    "                    self._o_prime.append( sigmoid(np.matmul(X, self.w_[i]) + self.b_[i]) * (1 - sigmoid(np.matmul(X, self.w_[i]) + self.b_[i])) )\n",
    "            else:\n",
    "                if self.hidden_activation == 'relu':\n",
    "                    self._o.append(np.maximum(np.matmul(self._o[i-1], self.w_[i]) + self.b_[i], 0))\n",
    "                    self._o_prime.append(np.heaviside(np.matmul(self._o[i-1], self.w_[i]) + self.b_[i], 0))\n",
    "                    \n",
    "                if self.hidden_activation == 'sigmoid':\n",
    "                    self._o.append(sigmoid(np.matmul(self._o[i-1], self.w_[i]) + self.b_[i]))\n",
    "                    self._o_prime.append( sigmoid(np.matmul(self._o[i-1], self.w_[i]) + self.b_[i]) * (1 - sigmoid(np.matmul(self._o[i-1], self.w_[i]) + self.b_[i])) )\n",
    "                    \n",
    "        if self.output_activation == 'relu':\n",
    "            self._o_prime.append(np.heaviside(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers], 0))\n",
    "            return np.maximum(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers], 0)\n",
    "        \n",
    "        if self.output_activation == 'sigmoid':\n",
    "            self._o_prime.append( sigmoid(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers]) * (1 - sigmoid(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers])) )\n",
    "            return sigmoid(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers])\n",
    "        \n",
    "        if self.output_activation == 'softmax':\n",
    "            return softmax(np.matmul(self._o[self.n_layers-1], self.w_[self.n_layers]) + self.b_[self.n_layers])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "13ef6640-485f-4f5f-a2d2-6795b5286faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = FullyconnectedNN(output_activation='sigmoid', hidden_activation='relu', learning_rate=0.01, n_layers= 5, n_neurons = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "3e4e6023-26b1-4356-8ea8-9996a286e0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-519-5f14ddc36bf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-506-2248c426b1ac>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_o_prime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (2,) "
     ]
    }
   ],
   "source": [
    "nn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "683b9801-eeac-4122-9667-04ecf30e2975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.471, 2.862])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "84ea3cd2-a33e-47c1-a42c-e73a58d69ebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-501-c8ab78cc2c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_o_prime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "self._d.append( self._o_prime[-i].mean(axis = 0) *  np.dot(nn.w_[-i], nn._d[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "cb388c47-2eae-4700-86e5-90183d238c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24998571, 0.24999193])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn._o_prime[-2].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "f61dba84-87da-4e11-bc83-ac566c68ec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00031228e-06, 5.70691916e-07],\n",
       "       [3.49109263e-07, 2.29445079e-07]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(nn.w_[-2],nn._d[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "d14a50d9-97dc-4e07-9744-813893ac2f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01579213, 0.00767435],\n",
       "       [0.00469474, 0.0054256 ]])"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.w_[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "bc2ca2b5-0a32-4f51-80d3-9d908fbda403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00016888,  0.00116183])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(nn.w_[-1], nn._d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "6e4331a4-cbb6-4e9a-813a-ca9042750ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05331239, 0.06453249])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn._o[-2].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c2ab9-e768-403e-9f53-088438ba9582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
